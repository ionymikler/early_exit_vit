dataset:
  channels_num: &dataset__channels_num 3
  image_size: &dataset__image_size 224 # CIFAR-100 image size
  num_classes: &dataset__num_clases 100 # CIFAR-100 number of classes

model:
  # values here are described in the Vit.__init__ method
  # Pairing some params from 'dataset' to 'vit' to avoid duplication
  channels_num: *dataset__channels_num
  image_size: *dataset__image_size
  num_classes: *dataset__num_clases
  
  pool: 'cls'
  embed_depth: &model__embed_depth 768 # 'hidden_size' in LGViT
  patch_size: 16 
  num_attn_heads: 12 # 'num_attention_heads' in LGViT
  general_dropout: 0.0 
  transformer_dropout: 0.0 
  mlp_dim: 3072 # 'intermediate_size' in LGVIT
  dim_head: 64 # computed as config.hidden_size / config.num_attention_heads in LGVIT
  num_layers_transformer: 12 # 'num_hidden_layers' in LGViT 
  enable_export: False # if 'True' the model will be created for onnx export (the flow control will be done with torch.cond)

  early_exit_config:
    enabled: True
    # Same as the pre-trained model
    exit_strategy: confidence
    confidence_threshold: 0.9 # overrides the threshold for all early exits

    embed_depth: *model__embed_depth
    num_classes: *dataset__num_clases
    num_attn_heads: 8

    exits: # [position, type, [kwargs] ]
      - [3, 'conv1_1']
      - [4, 'conv1_1']
      - [5, 'conv2_1']
      - [6, 'conv2_1']
      - [7, 'attention', {sr_ratio: 2}] # in LGVIT 'attention_r2'
      - [8, 'attention', {sr_ratio: 2}]
      - [9, 'attention', {sr_ratio: 3}]
      - [10, 'attention', {sr_ratio: 3}]